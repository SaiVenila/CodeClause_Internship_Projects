{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAfs0wQAxJL0"
      },
      "outputs": [],
      "source": [
        "# *** CODECLAUSE : PROJECT 4 ***\n",
        "# *** PREDICTION OF THE NEXT WORD ***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import regex as re"
      ],
      "metadata": {
        "id": "oCuyv1Xjy83b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_to_sentence_list(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Splitting the text into sentences using\n",
        "    # delimiters like '.', '?', and '!'\n",
        "    sentences = [sentence.strip() for sentence in re.split(\n",
        "        r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "file_path = 'pizza.txt'\n",
        "text_data = file_to_sentence_list(file_path)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for line in text_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences and split into predictors and label\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(\n",
        "    input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# Convert target data to one-hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "B39syIcNzBRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10,\n",
        "                    input_length=max_sequence_len-1))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2rIEZ8YX09Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKjIVm3_zPVJ",
        "outputId": "d0c619d2-887e-41de-a095-f53423d12079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.5715 - accuracy: 0.9109\n",
            "Epoch 2/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.5584 - accuracy: 0.9128\n",
            "Epoch 3/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.5454 - accuracy: 0.9140\n",
            "Epoch 4/100\n",
            "51/51 [==============================] - 3s 66ms/step - loss: 0.5329 - accuracy: 0.9158\n",
            "Epoch 5/100\n",
            "51/51 [==============================] - 2s 45ms/step - loss: 0.5204 - accuracy: 0.9201\n",
            "Epoch 6/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.5091 - accuracy: 0.9232\n",
            "Epoch 7/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.4958 - accuracy: 0.9177\n",
            "Epoch 8/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.4844 - accuracy: 0.9244\n",
            "Epoch 9/100\n",
            "51/51 [==============================] - 3s 67ms/step - loss: 0.4739 - accuracy: 0.9257\n",
            "Epoch 10/100\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.4636 - accuracy: 0.9275\n",
            "Epoch 11/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.4514 - accuracy: 0.9300\n",
            "Epoch 12/100\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.4430 - accuracy: 0.9251\n",
            "Epoch 13/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.4332 - accuracy: 0.9300\n",
            "Epoch 14/100\n",
            "51/51 [==============================] - 3s 66ms/step - loss: 0.4240 - accuracy: 0.9287\n",
            "Epoch 15/100\n",
            "51/51 [==============================] - 2s 45ms/step - loss: 0.4144 - accuracy: 0.9355\n",
            "Epoch 16/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.4043 - accuracy: 0.9343\n",
            "Epoch 17/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3971 - accuracy: 0.9367\n",
            "Epoch 18/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3900 - accuracy: 0.9367\n",
            "Epoch 19/100\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.3799 - accuracy: 0.9367\n",
            "Epoch 20/100\n",
            "51/51 [==============================] - 3s 54ms/step - loss: 0.3726 - accuracy: 0.9380\n",
            "Epoch 21/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3646 - accuracy: 0.9398\n",
            "Epoch 22/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3585 - accuracy: 0.9404\n",
            "Epoch 23/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3514 - accuracy: 0.9404\n",
            "Epoch 24/100\n",
            "51/51 [==============================] - 2s 48ms/step - loss: 0.3434 - accuracy: 0.9416\n",
            "Epoch 25/100\n",
            "51/51 [==============================] - 3s 63ms/step - loss: 0.3377 - accuracy: 0.9416\n",
            "Epoch 26/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3322 - accuracy: 0.9398\n",
            "Epoch 27/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.3260 - accuracy: 0.9429\n",
            "Epoch 28/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.3187 - accuracy: 0.9423\n",
            "Epoch 29/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3133 - accuracy: 0.9435\n",
            "Epoch 30/100\n",
            "51/51 [==============================] - 3s 69ms/step - loss: 0.3065 - accuracy: 0.9423\n",
            "Epoch 31/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.3023 - accuracy: 0.9453\n",
            "Epoch 32/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2970 - accuracy: 0.9447\n",
            "Epoch 33/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.2920 - accuracy: 0.9429\n",
            "Epoch 34/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2844 - accuracy: 0.9435\n",
            "Epoch 35/100\n",
            "51/51 [==============================] - 3s 69ms/step - loss: 0.2802 - accuracy: 0.9435\n",
            "Epoch 36/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2752 - accuracy: 0.9453\n",
            "Epoch 37/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2709 - accuracy: 0.9484\n",
            "Epoch 38/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2678 - accuracy: 0.9453\n",
            "Epoch 39/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2622 - accuracy: 0.9466\n",
            "Epoch 40/100\n",
            "51/51 [==============================] - 3s 58ms/step - loss: 0.2579 - accuracy: 0.9466\n",
            "Epoch 41/100\n",
            "51/51 [==============================] - 3s 52ms/step - loss: 0.2544 - accuracy: 0.9484\n",
            "Epoch 42/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2496 - accuracy: 0.9515\n",
            "Epoch 43/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2460 - accuracy: 0.9496\n",
            "Epoch 44/100\n",
            "51/51 [==============================] - 2s 42ms/step - loss: 0.2422 - accuracy: 0.9502\n",
            "Epoch 45/100\n",
            "51/51 [==============================] - 3s 50ms/step - loss: 0.2388 - accuracy: 0.9490\n",
            "Epoch 46/100\n",
            "51/51 [==============================] - 3s 62ms/step - loss: 0.2341 - accuracy: 0.9533\n",
            "Epoch 47/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2311 - accuracy: 0.9502\n",
            "Epoch 48/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2271 - accuracy: 0.9545\n",
            "Epoch 49/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2231 - accuracy: 0.9533\n",
            "Epoch 50/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.2203 - accuracy: 0.9539\n",
            "Epoch 51/100\n",
            "51/51 [==============================] - 3s 68ms/step - loss: 0.2179 - accuracy: 0.9533\n",
            "Epoch 52/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.2136 - accuracy: 0.9576\n",
            "Epoch 53/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2121 - accuracy: 0.9533\n",
            "Epoch 54/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.2071 - accuracy: 0.9521\n",
            "Epoch 55/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.2048 - accuracy: 0.9570\n",
            "Epoch 56/100\n",
            "51/51 [==============================] - 4s 70ms/step - loss: 0.2020 - accuracy: 0.9570\n",
            "Epoch 57/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1991 - accuracy: 0.9576\n",
            "Epoch 58/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1961 - accuracy: 0.9552\n",
            "Epoch 59/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1933 - accuracy: 0.9595\n",
            "Epoch 60/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1898 - accuracy: 0.9570\n",
            "Epoch 61/100\n",
            "51/51 [==============================] - 4s 69ms/step - loss: 0.1888 - accuracy: 0.9564\n",
            "Epoch 62/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1867 - accuracy: 0.9595\n",
            "Epoch 63/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1826 - accuracy: 0.9582\n",
            "Epoch 64/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1814 - accuracy: 0.9588\n",
            "Epoch 65/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1783 - accuracy: 0.9601\n",
            "Epoch 66/100\n",
            "51/51 [==============================] - 3s 61ms/step - loss: 0.1756 - accuracy: 0.9595\n",
            "Epoch 67/100\n",
            "51/51 [==============================] - 3s 51ms/step - loss: 0.1735 - accuracy: 0.9607\n",
            "Epoch 68/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1720 - accuracy: 0.9588\n",
            "Epoch 69/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1684 - accuracy: 0.9601\n",
            "Epoch 70/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1670 - accuracy: 0.9595\n",
            "Epoch 71/100\n",
            "51/51 [==============================] - 3s 57ms/step - loss: 0.1642 - accuracy: 0.9613\n",
            "Epoch 72/100\n",
            "51/51 [==============================] - 3s 55ms/step - loss: 0.1629 - accuracy: 0.9613\n",
            "Epoch 73/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1618 - accuracy: 0.9607\n",
            "Epoch 74/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1597 - accuracy: 0.9619\n",
            "Epoch 75/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1585 - accuracy: 0.9613\n",
            "Epoch 76/100\n",
            "51/51 [==============================] - 3s 49ms/step - loss: 0.1544 - accuracy: 0.9619\n",
            "Epoch 77/100\n",
            "51/51 [==============================] - 3s 64ms/step - loss: 0.1538 - accuracy: 0.9650\n",
            "Epoch 78/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1523 - accuracy: 0.9631\n",
            "Epoch 79/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1502 - accuracy: 0.9638\n",
            "Epoch 80/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1516 - accuracy: 0.9607\n",
            "Epoch 81/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1471 - accuracy: 0.9613\n",
            "Epoch 82/100\n",
            "51/51 [==============================] - 4s 71ms/step - loss: 0.1435 - accuracy: 0.9625\n",
            "Epoch 83/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1421 - accuracy: 0.9644\n",
            "Epoch 84/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1422 - accuracy: 0.9638\n",
            "Epoch 85/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1391 - accuracy: 0.9662\n",
            "Epoch 86/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1387 - accuracy: 0.9650\n",
            "Epoch 87/100\n",
            "51/51 [==============================] - 4s 71ms/step - loss: 0.1365 - accuracy: 0.9662\n",
            "Epoch 88/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1345 - accuracy: 0.9656\n",
            "Epoch 89/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1354 - accuracy: 0.9656\n",
            "Epoch 90/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1318 - accuracy: 0.9638\n",
            "Epoch 91/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1306 - accuracy: 0.9638\n",
            "Epoch 92/100\n",
            "51/51 [==============================] - 3s 69ms/step - loss: 0.1289 - accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1284 - accuracy: 0.9662\n",
            "Epoch 94/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1252 - accuracy: 0.9674\n",
            "Epoch 95/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1245 - accuracy: 0.9674\n",
            "Epoch 96/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1250 - accuracy: 0.9668\n",
            "Epoch 97/100\n",
            "51/51 [==============================] - 3s 63ms/step - loss: 0.1224 - accuracy: 0.9674\n",
            "Epoch 98/100\n",
            "51/51 [==============================] - 3s 50ms/step - loss: 0.1211 - accuracy: 0.9674\n",
            "Epoch 99/100\n",
            "51/51 [==============================] - 2s 43ms/step - loss: 0.1206 - accuracy: 0.9650\n",
            "Epoch 100/100\n",
            "51/51 [==============================] - 2s 44ms/step - loss: 0.1182 - accuracy: 0.9662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7db6c86d41f0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate next word predictions\n",
        "seed_text = \"Pizza have different \"\n",
        "next_words = 5\n",
        "\n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences(\n",
        "        [token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted_probs = model.predict(token_list)\n",
        "    predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnicTVPezSnU",
        "outputId": "56be91cc-6aa8-4fe6-a074-465fb4bb36a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 436ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Next predicted words: Pizza have different  advancements we may see innovations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doxpeh9SzYkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}